# Service Ports
MANAGER_SERVICE_PORT=8082
REQUIREMENTS_SERVICE_PORT=8081
TRANSCRIPTION_SERVICE_PORT=8080

# LLM Provider Settings (choose one: openrouter, openai, or ollama)
LLM_PROVIDER=ollama

# --- OpenRouter Settings (if LLM_PROVIDER is "openrouter") ---
OPENROUTER_API_KEY=sk-or-v1-
OPENROUTER_MODEL=meta-llama/llama-3.3-70b-instruct

# --- OpenAI Settings (if LLM_PROVIDER is "openai") ---
OPENAI_API_KEY=sk-proj-
OPENAI_MODEL=gpt-4o-mini

# --- Ollama Settings (if LLM_PROVIDER is "ollama") ---
OLLAMA_URL=http://localhost:11434/v1
OLLAMA_MODEL=qwen2.5:7b-instruct-q4_K_M

# URL Endpoints for Inter-Service Communication
VOICE_SERVICE_URL=http://localhost:8080/api/v0/
MEETING_SERVICE_URL=http://localhost:8081/api/v0/
MANAGER_SERVICE_URL=http://localhost:8082/api/v0/
CODE_GENERATION_SERVICE_URL=http://localhost:8083

# Transcription Service Specific Settings
# Set transcription method: "local" for local (faster-whisper) or "rest" for REST API call
TRANSCRIPTION_METHOD=local

# Set the task to transcribe or translate
TASK=translate

# For local transcription using faster-whisper, specify the model size
LOCAL_MODEL_SIZE=medium

# Set to "True" to use CUDA for GPU acceleration or "False" to use the CPU
USE_CUDA=True

# Audio device index to use for capturing audio with PyAudio
AUDIO_DEVICE_INDEX=1